
@import org.openmole.site.tools._
@import org.openmole.site._
@import org.openmole.site.NativeDocPageCommons._





  @p Let's study two concrete use cases that take an existing application, package it with CARE, and embed it in OpenMOLE. You should be able to achieve exactly the same process with almost any executable running on Linux. We've chosen an @a("R code", href := DocumentationPages.native.file + "#AnexamplewithR") and a @a("Python script", href := DocumentationPages.native.file + "#AnotherexamplewithaPythonscript").

@sect{@shared.nativeModel.rExample}
    Our first example is an R script contained in a file @i{myscript.R}. We want to distribute the execution of this R code to the @a("EGI grid", href := DocumentationPages.egi.file).

    @p First your script should run in headless mode with no input required from the user during the execution. Your script should produce files or write its results to the standard output so that OpenMOLE can retrieve them from the remote execution environment.

    @p Here is an example R script matching these criteria:
    @br @hl.highlight("""
      args<-commandArgs(trailingOnly = TRUE)
      data<-read.csv("data.csv",header=T,sep=",")
      result<-as.numeric(args[1])*data
      write.csv(result,"result.csv", row.names=FALSE)""", "R")

    @p With an example @i{data.csv}:
    @br @hl.highlight("""
    h1,h2,h3
    7,8,9
    9,7,3
    1,1,1""", "plain")

    @p This reads a file called @i{data.csv}, multiply its content by a number provided on the command line and writes the result to an output file called @i{results.csv}. To call this script from the command line you should type: @hl.highlight("R -f script.R --slave --args 4", "plain"), considering you have @i{R} installed on your system.

    @p Once the script is up and running, remember that the first step to run it from OpenMOLE is to package it. This is done using CARE on your system.
    @br @hl.highlight("""care -r /home/reuillon/ -o r.tgz.bin R -f script.R --slave --args 4""", "plain")

    @p Notice how the command line is identical to the original one. The call to the @i{R} script remains unchanged, as CARE and its options are inserted at the beginning of the command line.

    @p A @i{care.tgz.bin} file is created. It is an archive containing a portable version of your execution. It can be extracted and executed on any other Linux platform.

    @p The method described here packages everything, including @i{R} itself! Therefore there is no need to install @i{R} on the target execution machine. All that is needed is for the remote execution host to run Linux, which is the case for the vast majority of (decent) high performance computing environments.

    @p Packaging an application is done @b{once and for all} by running the original application against CARE. CARE's re-execution mechanisms allows you to change the original command line when re-running your application. This way you can update the parameters passed on the command line and the re-execution will be impacted accordingly. As long as all the configuration files, libraries, ... were used during the original execution, there is no need to package the application multiple times with different input parameters.

    @p You can now upload this archive to your OpenMOLE workspace along with a @i{data.csv} file in a subfolder named data. Let's now explore a complete combination of all the data files with OpenMOLE. The input data files are located in @i{data} and the result files are written to a folder called @i{results}. A second input parameter is a numeric value @i{i} ranging from 1 to 10. The corresponding OpenMOLE script looks like this:
    @p @hl.openmole("""
    // Declare the variable
    val i = Val[Double]
    val input = Val[File]
    val inputName = Val[String]
    val output = Val[File]

    // R task
    // "path/on/your/system" is a path on the original system on which you packaged R
    val rTask = CARETask(workDirectory / "r.tgz.bin", "R --slave -f script.R --args ${i}") set (
      (inputs, outputs) += (i, inputName),
      inputFiles += (input, "data.csv"),
      outputFiles += ("result.csv", output)
    )

    val exploration =
      ExplorationTask(
        (i in (1.0 to 10.0 by 1.0)) x
        (input in (workDirectory / "data").files withName inputName)
      )

    val copy = CopyFileHook(output, workDirectory / "result" / "${inputName}-${i}.csv")
    exploration -< (rTask hook copy hook ToStringHook())""")

    @p The @hl.openmole("CARETask") performs two actions: it first unarchives the CARE container by running @hl.highlight("r.tgz.bin", "plain"). Then the actual execution takes place as a second command. Note that for each execution of the @i("CARETask"), any command starting with @i("/") is @b{relative to the root of the CARE archive}, and @b{any other command is executed in the current directory}. The current directory @b{defaults to the original packaging directory}.

    @p Several notions from OpenMOLE are reused in this example. If you're not too familiar with
    @a("Hooks", href := DocumentationPages.hook.file) or
    @a("Samplings", href := DocumentationPages.advancedSampling.file), check the relevant sections of the
    documentation.

@sect{@shared.nativeModel.pythonExample}
    The toy Python script for this test case is:
    @br @hl.highlight("""
    import sys
    f = open(sys.argv[2], 'w')
    f.write(sys.argv[1])
    exit(0)""", "python")

    @p This script is saved to @i{hello.py}. We first package it using CARE:
    @hl.highlight("""care -o hello.tgz.bin python hello.py 42 test.txt""", "plain")

    @p We can now run it in OpenMOLE using the following script:
    @br @hl.openmole("""
    // Declare the variable
    val arg = Val[Int]
    val output = Val[File]

    // python task
    val pythonTask =
      CARETask(workDirectory / "hello.tgz.bin", "python hello.py ${arg} output.txt") set (
        inputs += arg,
        outputFiles += ("output.txt", output),
        outputs += arg
      )

    val exploration = ExplorationTask(arg in (0 to 10))

    val copy = CopyFileHook(output, workDirectory / "hello${arg}.txt")
    val env = LocalEnvironment(4)
    exploration -< (pythonTask hook copy on env by 2)""")

   @p Again notions from OpenMOLE are reused in this example. If you're not too familiar with @a("Environments", href := DocumentationPages.environment.file) or @i{Groupings}, check the relevant sections of the documentation.

   @p Two things should be noted from these examples:
     @ul
       @li{The procedure to package an application @b{is always the same} regardless of the underlying programming language / framework used.}
       @li{The CARETask is not different from the @a("SystemExecTask", href := DocumentationPages.native.file + "#Usingalocalexecutable(innonportabletasks)"), to the extent of the archive given as a first parameter.}
    These two aspects make it really easy to embed native applications in OpenMOLE.

@sect{@shared.nativeModel.advancedOptions}
    The @i{CARETask} can be customised to fit the needs of a specific application. For instance, some applications disregarding standards might not return the expected 0 value upon completion. The return value of the application is used by OpenMOLE to determine whether the task has been successfully executed, or needs to be re-executed. Setting the boolean flag @hl.openmoleNoTest("errorOnReturnValue") to @i{false} will prevent OpenMOLE from re-scheduling a @i{CARETask} that have reported a return code different from 0. You can also get the return code in a variable using the @hl.openmoleNoTest("returnValue") setting.

    @p Another default behaviour is to print the standard and error outputs of each task in the OpenMOLE console. Such raw prints might not be suitable when a very large number of tasks is involved or that further processing are to be performed on the outputs. A @i{CARETask}'s standard and error outputs can be assigned to OpenMOLE variable and thus injected in the dataflow by summoning respectively the @hl.openmoleNoTest("stdOut") and @hl.openmoleNoTest("stdErr") actions on the task.

    @p As any other process, the applications contained in OpenMOLE's native tasks accept environment variables to influence their behaviour.
    Variables from the dataflow can be injected as environment variables using the @hl.openmoleNoTest{environmentVariable += (variable, "variableName")} field.
    If no name is specified, the environment variable is named after the OpenMOLE variable.
    Environment variables injected from the dataflow are @b{inserted in the pre-existing set of environment variables from the execution host}. This shows particularly useful to preserve
    the behaviour of some toolkits when executed on local environments (ssh, clusters, ...) where users control their work environment.

    @p The following snippet creates a task that employs the features described in this section:
    @br @hl.openmole("""
    // Declare the variable
    val output = Val[String]
    val error  = Val[String]
    val value = Val[Int]

    // Any task
    val pythonTask =
      CARETask("hello.tgz.bin", "python hello.py") set (
        stdOut := output,
        stdErr := error,
        returnValue := value,
        environmentVariable += (value, "I_AM_AN_ENV_VAR")
      )""")

    @p You will note that @b{options holding a single value} are set using the @hl.openmoleNoTest(":=") operator. Also, the OpenMOLE variables containing the standard and error outputs are @b{automatically marked as outputs} of the task, and must not be added to the @hl.openmoleNoTest("outputs") list.

@h3
    Using local resources
@p
    To access data present on the execution node (outside the CARE filesystem) you should use a dedicated option of the @i{CARETask}: @i{hostFiles}. This option takes the path of a file on the execution host and binds it to the same path in the CARE filesystem. Optionally you can provide a second argument to specify the path explicitly. For instance:
    @br @hl.openmole("""
      val careTask = CARETask("care.tgz.bin", "executable arg1 arg2 /path/to/my/file /virtual/path arg4") set (
        hostFiles += ("/path/to/my/file"),
        hostFiles += ("/path/to/another/file", "/virtual/path")
      )""")

    @p This CARE?task will thus be able to access @i{/path/to/my/file} and @i{/virtual/path}.

  @p{Using a local executable (in non portable tasks)}
    @p The @i{CARETask} was designed to be portable from one machine to another. However, some use-cases require executing specific commands installed on a given cluster. To achieve that you should use another task called @i{SystemExecTask}. This task is made to launch native commands on the execution host. There is two modes for using this task:
    @ul
      @li{Calling a command that is @b{assumed to be available on any execution node of the environment}. The command will be looked for in the system as it would from a traditional command line: searching in the default @i{PATH} or an absolute location.}
      @li{Copying a @b{local script not installed on the remote environment}. Applications and scripts can be copied to the task's work directory using the @hl.openmoleNoTest("resources") field. Please note that contrary to the CARETask, there is @b{no guarantee that an application passed as a resource to a SystemExecTask will re-execute successfully on a remote environment}}.

    @p The @i{SystemExecTask} accepts an arbitrary number of commands. These commands will be @b{executed sequentially on the same execution node} where the task is instantiated. In other words, it is not possible to split the execution of multiple commands grouped in the same @i{SystemExecTask}.

    @p The following example first copies and runs a bash script on the remote host, before calling the remote's host @hl.highlight("/bin/hostname", "plain"). Both commands' standard and error outputs are gathered and concatenated to a single OpenMOLE variable: respectively @hl.openmoleNoTest("stdOut") and @hl.openmoleNoTest("stdErr").  To achieve that you should use a @i{SystemExecTask}:
     @br @hl.openmole("""
      // Declare the variable
      val output = Val[String]
      val error  = Val[String]

      // Any task
      val scriptTask =
        SystemExecTask("bash script.sh", "hostname") set (
          resources += workDirectory / "script.sh",
          stdOut := output,
          stdErr := error
        )

       scriptTask hook ToStringHook()""")

    @p In this case the bash script might depend on program installed on the remote host. Similarly, we @b{assume the presence} of @hl.highlight("/bin/hostname", "plain") on the execution node. Therefore this task cannot be considered as portable.

    @p Note that each execution is isolated in separate folder on the execution host and that the task execution is considered as failed if the script return a value different from 0. If you need another behaviour you can use the same advanced options as the @i{CARETask} regarding the return code.
